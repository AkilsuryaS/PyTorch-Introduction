{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"A100","authorship_tag":"ABX9TyOn/9GnFUzJiMrF5RDrlzPG"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"RfU4UwSYqcCb","executionInfo":{"status":"ok","timestamp":1723157681919,"user_tz":420,"elapsed":3727,"user":{"displayName":"Akilsurya S","userId":"11381451638417927507"}}},"outputs":[],"source":["import torch\n","import numpy as np"]},{"cell_type":"markdown","source":["# Tensors\n","\n","- Tensors are building blocks of any deep learning network.\n","- They are used to represent all the different types of data be it images, sound, text data, etc.\n","- Tensors are **order N-matrix**\n","\n","**For example:**\n","* If N=1, tensor will basically be a *vector* (1-D matrix)\n","* If N=2, tensor will basically be a *matrix* (2-D matrix)\n","\n","**Why Tensors and not Numpy arrays?**\n","- NumPy only supports CPU computation\n","- Tensor class supports automatic differentiation\n","\n","\n","**Let's start by importing PyTorch library and understand some of the basic functions on tensors.**\n","\n","\n","# Scalar\n","\n","- rank-0 tensor\n","\n"],"metadata":{"id":"1fjLc5I6tNaF"}},{"cell_type":"code","source":["t = torch.tensor(1.)\n","print(t)\n","print('\\n size:',t.shape, sep=\"\\n\")\n","print()\n","print('\\n number of dimensions:', t.dim(), sep='\\n')\n","print('\\n Data Type:', t.dtype, sep='\\n')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DOAcDPZ4vp7E","executionInfo":{"status":"ok","timestamp":1723157681919,"user_tz":420,"elapsed":23,"user":{"displayName":"Akilsurya S","userId":"11381451638417927507"}},"outputId":"aaa200d7-666c-40f4-b2af-2ef2f1b354e1"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(1.)\n","\n"," size:\n","torch.Size([])\n","\n","\n"," number of dimensions:\n","0\n","\n"," Data Type:\n","torch.float32\n"]}]},{"cell_type":"markdown","source":["# Vector\n","- rank-1 tensor"],"metadata":{"id":"kprYcxCdwDCc"}},{"cell_type":"code","source":["t = torch.tensor([1,2])\n","print(t)\n","print()\n","print(\"\\n size\", t.shape, sep='\\n')\n","print()\n","print('\\n Number of dimensions:', t.dim(), sep='\\n')\n","print()\n","print('\\n data type:', t.dtype, sep='\\n')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mLk_yQI6wLOF","executionInfo":{"status":"ok","timestamp":1723157681919,"user_tz":420,"elapsed":11,"user":{"displayName":"Akilsurya S","userId":"11381451638417927507"}},"outputId":"01fbbae4-fd6a-4303-94f8-8aeeec93c111"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([1, 2])\n","\n","\n"," size\n","torch.Size([2])\n","\n","\n"," Number of dimensions:\n","1\n","\n","\n"," data type:\n","torch.int64\n"]}]},{"cell_type":"markdown","source":["## <font color = 'pickle'>**Matrix**\n","- rank 2 tensor\n","\n","Matrices are 2-d arrays with size `n x m`. Here, n: number of rows and m: number of columns.\n","\n","If `m = n`, then the matrix is known as a `square matrix`.\n","\n","Precisely, matrices can be represented as:\n","$$\\mathbf{X}=\\begin{bmatrix} x_{11} & x_{12} & \\cdots & x_{1n} \\\\ x_{21} & x_{22} & \\cdots & x_{2n} \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ x_{m1} & x_{m2} & \\cdots & x_{mn} \\\\ \\end{bmatrix}$$\n","<br>\n","\n"],"metadata":{"id":"q8w95xnCwxjD"}},{"cell_type":"code","source":["t = torch.tensor([\n","    [1., 2, 3],\n","    [4,5,6],\n","    [7,8,9]\n","])\n","\n","print(t)\n","print()\n","print(\"\\n size\", t.shape, sep='\\n')\n","print()\n","print('\\n Number of dimensions:', t.dim(), sep='\\n')\n","print()\n","print('\\n data type:', t.dtype, sep='\\n')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7dgH2_K3w9fq","executionInfo":{"status":"ok","timestamp":1723157681919,"user_tz":420,"elapsed":10,"user":{"displayName":"Akilsurya S","userId":"11381451638417927507"}},"outputId":"62ab8a54-7758-4bc6-f3e2-6d82174fe08a"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[1., 2., 3.],\n","        [4., 5., 6.],\n","        [7., 8., 9.]])\n","\n","\n"," size\n","torch.Size([3, 3])\n","\n","\n"," Number of dimensions:\n","2\n","\n","\n"," data type:\n","torch.float32\n"]}]},{"cell_type":"markdown","source":["# Higher Order Tensors\n","- rank-3 tensor"],"metadata":{"id":"IKv4gcPWxMTJ"}},{"cell_type":"code","source":["t = torch.tensor([\n","    [[1,2], [3,4]],\n","    [[5,6],[7,8]],\n","    [[9,10],[11,12]]\n","])\n","\n","print(t)\n","print()\n","print(\"\\n size\", t.shape, sep='\\n')\n","print()\n","print('\\n Number of dimensions:', t.dim(), sep='\\n')\n","print()\n","print('\\n data type:', t.dtype, sep='\\n')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h9xvbYEXyJ3p","executionInfo":{"status":"ok","timestamp":1723157681919,"user_tz":420,"elapsed":9,"user":{"displayName":"Akilsurya S","userId":"11381451638417927507"}},"outputId":"dfa9fb11-7935-4d73-cf9b-07d5391ced98"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[[ 1,  2],\n","         [ 3,  4]],\n","\n","        [[ 5,  6],\n","         [ 7,  8]],\n","\n","        [[ 9, 10],\n","         [11, 12]]])\n","\n","\n"," size\n","torch.Size([3, 2, 2])\n","\n","\n"," Number of dimensions:\n","3\n","\n","\n"," data type:\n","torch.int64\n"]}]},{"cell_type":"code","source":["# Python List\n","scalar = 4\n","type(scalar)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d-H-wh8MyZcV","executionInfo":{"status":"ok","timestamp":1723157681919,"user_tz":420,"elapsed":9,"user":{"displayName":"Akilsurya S","userId":"11381451638417927507"}},"outputId":"9602f948-7e63-4832-9b55-1f83f4947b63"},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["int"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["my_list = [[1,2],[3,4]]\n","type(my_list)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iE8oLIzuzQDK","executionInfo":{"status":"ok","timestamp":1723157681919,"user_tz":420,"elapsed":8,"user":{"displayName":"Akilsurya S","userId":"11381451638417927507"}},"outputId":"e195d0bc-d53c-4879-f8f7-3ef020d0b0aa"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["list"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["my_tensor = torch.tensor([[1,2],[3,4]])\n","print(type(my_tensor))\n","print(t)\n","print()\n","print('\\n Data type:', my_tensor.dtype, sep='\\n')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h53KzotZzUOS","executionInfo":{"status":"ok","timestamp":1723157681919,"user_tz":420,"elapsed":8,"user":{"displayName":"Akilsurya S","userId":"11381451638417927507"}},"outputId":"d6ccde5e-8c6d-43e9-c6c2-97d9d626ac60"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'torch.Tensor'>\n","tensor([[[ 1,  2],\n","         [ 3,  4]],\n","\n","        [[ 5,  6],\n","         [ 7,  8]],\n","\n","        [[ 9, 10],\n","         [11, 12]]])\n","\n","\n"," Data type:\n","torch.int64\n"]}]},{"cell_type":"code","source":["my_tensor = torch.tensor([[1.,2],[3,4]])\n","print(type(my_tensor))\n","print(t)\n","print()\n","print('\\n Data type:', my_tensor.dtype, sep='\\n')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8CiuogDBzq3a","executionInfo":{"status":"ok","timestamp":1723157681919,"user_tz":420,"elapsed":7,"user":{"displayName":"Akilsurya S","userId":"11381451638417927507"}},"outputId":"fdae236c-7ede-4c81-dc2a-64a139633ebe"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'torch.Tensor'>\n","tensor([[[ 1,  2],\n","         [ 3,  4]],\n","\n","        [[ 5,  6],\n","         [ 7,  8]],\n","\n","        [[ 9, 10],\n","         [11, 12]]])\n","\n","\n"," Data type:\n","torch.float32\n"]}]},{"cell_type":"markdown","source":["# <font color = 'pickle'>**Difference between list and Array/tensor**</font>\n","\n","| <font size =5> Python List                       | <font size =5>Tensor/Array                     |\n","|-----------------------------------|----------------------------------|\n","| <font size =5>Mixed types allowed               | <font size =5>Same type required               |\n","|<font size =5> Elements can be added or removed  | <font size =5>Elements cannot be added or removed               \n","| <font size =5>Basic Python operations           | <font size =5>Supports mathematical operations                \n","|<font size =5>Numerical Computtaions are slow    |<font size =5>Numerical Computtaions are fast\n","\n"],"metadata":{"id":"lCFId26Hzy4x"}},{"cell_type":"markdown","source":["# Conversion to other Python Objects"],"metadata":{"id":"V_KbuF3B6uPG"}},{"cell_type":"code","source":["# Initializing a tensor\n","t = torch.arange(10)\n","\n","print(\"Initial Tensor:\",t)\n","print()\n","\n","# Converting tensor t to numpy array using numpy() method\n","arr = t.numpy()\n","print(\"Converting Tensor into a Numpy Array:\", arr)\n","\n","# Converting numpy array to tensor T using tensor() method\n","T = torch.tensor(arr)\n","print(\"Converting Numpy array into a Tensor\", T)\n","\n","# Print datatype of arr and T\n","print()\n","print(f\"Dtype of arr: {arr.dtype}\")\n","print(f\"Dtype of T: {T.dtype}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EB_h0jPPz8rJ","executionInfo":{"status":"ok","timestamp":1723157681919,"user_tz":420,"elapsed":6,"user":{"displayName":"Akilsurya S","userId":"11381451638417927507"}},"outputId":"6bb9fd49-2403-423d-d1d4-102617a5a6cb"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Initial Tensor: tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n","\n","Converting Tensor into a Numpy Array: [0 1 2 3 4 5 6 7 8 9]\n","Converting Numpy array into a Tensor tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n","\n","Dtype of arr: int64\n","Dtype of T: torch.int64\n"]}]},{"cell_type":"markdown","source":["**Note:** We can also use `torch.from_numpy()` and `torch.as_tensor()` to convert numpy array to PyTorch tensor. However with these methods, the PyTorch tensor and the source NumPy array share the same memory. This means that changes to one affect the other. But, the `torch.tensor()` function always makes a copy."],"metadata":{"id":"fYiItyYv0_zk"}},{"cell_type":"code","source":["my_ndarray = np.arange(10)\n","t_from_numpy = torch.from_numpy(my_ndarray)\n","t_as_tensor = torch.as_tensor(my_ndarray)\n","t_Tensor = torch.tensor(my_ndarray)\n","\n","print(f\"tensor craeted using torch.from_numpy before changing np array: {t_from_numpy}\")\n","print(f\"tensor craeted using torch.as_tensor before changing np array : {t_as_tensor}\")\n","print(f\"tensor craeted using torch.tensor before changing np array    : {t_Tensor}\")\n","\n","# change numpy array\n","my_ndarray[2] = 1000\n","\n","print()\n","print(f\"tensor craeted using torch.from_numpy after changing np array: {t_from_numpy}\")\n","print(f\"tensor craeted using torch.as_tensor after changing np array : {t_as_tensor}\")\n","print(f\"tensor craeted using torch.tensor after changing np array    : {t_Tensor}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m7yhmI4H1ugQ","executionInfo":{"status":"ok","timestamp":1723157681919,"user_tz":420,"elapsed":6,"user":{"displayName":"Akilsurya S","userId":"11381451638417927507"}},"outputId":"ca54f634-0c5c-4fc2-e916-c0f59bcb2e56"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor craeted using torch.from_numpy before changing np array: tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n","tensor craeted using torch.as_tensor before changing np array : tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n","tensor craeted using torch.tensor before changing np array    : tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n","\n","tensor craeted using torch.from_numpy after changing np array: tensor([   0,    1, 1000,    3,    4,    5,    6,    7,    8,    9])\n","tensor craeted using torch.as_tensor after changing np array : tensor([   0,    1, 1000,    3,    4,    5,    6,    7,    8,    9])\n","tensor craeted using torch.tensor after changing np array    : tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n"]}]},{"cell_type":"code","source":["# Initializing a size-1 tensor\n","t = torch.tensor([10.5])\n","\n","# Printing tensor\n","print(t)\n","\n","# Accessing element of tensor using item function\n","# 'items' returns the value of the tensor as python number\n","# 'works only for tensors with single element'\n","\n","print(t.item())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a6YxyQnC2M0m","executionInfo":{"status":"ok","timestamp":1723157681919,"user_tz":420,"elapsed":6,"user":{"displayName":"Akilsurya S","userId":"11381451638417927507"}},"outputId":"1647e962-c31a-4135-b07f-1c8a0165afde"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([10.5000])\n","10.5\n"]}]},{"cell_type":"code","source":["# We can also convert the tensor to python list\n","t = torch.tensor([10,2])\n","print(t)\n","print()\n","print(\"Tensor converted into Python List..\", t.tolist())\n","print(type(t.tolist()))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FbAKtH0M24sF","executionInfo":{"status":"ok","timestamp":1723157681919,"user_tz":420,"elapsed":5,"user":{"displayName":"Akilsurya S","userId":"11381451638417927507"}},"outputId":"321ef3e5-0cb8-4c9a-bdb0-72da2192409b"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([10,  2])\n","\n","Tensor converted into Python List.. [10, 2]\n","<class 'list'>\n"]}]},{"cell_type":"markdown","source":["# Changing the shape of Tensors"],"metadata":{"id":"3uMovFMW3SPQ"}},{"cell_type":"code","source":["t = torch.arange(10)\n","print(t)\n","print('\\n size/shape of tensor:', t.shape, sep='\\n')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"n_7Twgpc3a14","executionInfo":{"status":"ok","timestamp":1723157681919,"user_tz":420,"elapsed":5,"user":{"displayName":"Akilsurya S","userId":"11381451638417927507"}},"outputId":"0abb083b-1f4d-4667-e25f-7bf16af18154"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n","\n"," size/shape of tensor:\n","torch.Size([10])\n"]}]},{"cell_type":"code","source":["t = t.view(5,2)\n","print(t)\n","print()\n","print('\\n size:', t.shape, sep='\\n')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kjyYB3AM4e0t","executionInfo":{"status":"ok","timestamp":1723157681919,"user_tz":420,"elapsed":4,"user":{"displayName":"Akilsurya S","userId":"11381451638417927507"}},"outputId":"4e6b5025-1bf3-4439-c449-738d499f1803"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[0, 1],\n","        [2, 3],\n","        [4, 5],\n","        [6, 7],\n","        [8, 9]])\n","\n","\n"," size:\n","torch.Size([5, 2])\n"]}]},{"cell_type":"code","source":["t = t.view(-1,5)\n","print(t)\n","print()\n","print('\\n size:', t.shape, sep='\\n')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cgRBCL7c4rxr","executionInfo":{"status":"ok","timestamp":1723157681919,"user_tz":420,"elapsed":4,"user":{"displayName":"Akilsurya S","userId":"11381451638417927507"}},"outputId":"d17f0827-0223-4bcd-c73a-ad44203606fc"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[0, 1, 2, 3, 4],\n","        [5, 6, 7, 8, 9]])\n","\n","\n"," size:\n","torch.Size([2, 5])\n"]}]},{"cell_type":"markdown","source":["# Changing the datatype of Tensors\n","\n","When creating tensor we can pass the dtype as an argument. We can also change the datatype of tensors using to() and type() methods. For a list of dtypes visit https://pytorch.org/docs/stable/tensor_attributes.html#torch.torch.dtype"],"metadata":{"id":"fGz1eJjn5IZm"}},{"cell_type":"code","source":["x = torch.tensor([8,9,-3], dtype = torch.int)\n","print(f\"Current tensor: {x}\")\n","print()\n","\n","# We can use type() method or to() method to change the datatype\n","print(f\"Old: {x.dtype}\")\n","\n","# change the datatype to int64 using type() method\n","x = x.type(dtype=torch.int64)\n","print(f\"New (using type() method): {x.dtype}\")\n","\n","# change the datatype to int32 using to() method\n","x = x.to(dtype = torch.int32)\n","print(f\"Newer (using to()method): {x.dtype}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ElVQRcAI5W3H","executionInfo":{"status":"ok","timestamp":1723157681919,"user_tz":420,"elapsed":4,"user":{"displayName":"Akilsurya S","userId":"11381451638417927507"}},"outputId":"b382e0fc-0e3f-4c05-d2eb-bfd7a2f7e5b1"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Current tensor: tensor([ 8,  9, -3], dtype=torch.int32)\n","\n","Old: torch.int32\n","New (using type() method): torch.int64\n","Newer (using to()method): torch.int32\n"]}]},{"cell_type":"markdown","source":["# Saving Memory - inplace operations\n","\n","*In-place operator are operations that change the content of a given Tensor without making a copy.*\n","\n","- Operations that have `a_` suffix are in-place. For example: `.add_()`. Operations like += or *= are also in-place operations.\n","\n","We can also perform in-place operation using the notation `Z[:] = <expression>`\n","\n","As in-place operations do not make a copy, they can save memory. However, we need to use them carefully. They can be **problematic when computing derivatives** because of an immediate loss of history.\n","\n"],"metadata":{"id":"qvFAnl-w8MwM"}},{"cell_type":"code","source":["a = torch.tensor(10)\n","print(a)\n","print(id(a))\n","\n","a+=1\n","print(a)\n","print(id(a))\n","a=a+1\n","print(a)\n","print(id(a))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5ciYLfXX9fJd","executionInfo":{"status":"ok","timestamp":1723157681919,"user_tz":420,"elapsed":3,"user":{"displayName":"Akilsurya S","userId":"11381451638417927507"}},"outputId":"11c79eb6-d0af-4022-bc23-baba06014fa7"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(10)\n","139629107648112\n","tensor(11)\n","139629107648112\n","tensor(12)\n","139629107648912\n"]}]},{"cell_type":"code","source":["b = torch.tensor(10)\n","print(b)\n","print(id(b))\n","b.add_(1)\n","print(b)\n","print(id(b))\n","b = b.add(1)\n","print(b)\n","print(id(b))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rYQdDTv99xBy","executionInfo":{"status":"ok","timestamp":1723157681919,"user_tz":420,"elapsed":3,"user":{"displayName":"Akilsurya S","userId":"11381451638417927507"}},"outputId":"5b2fda62-ed26-4da4-b09a-20bd7ed61ee8"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(10)\n","139629107650112\n","tensor(11)\n","139629107650112\n","tensor(12)\n","139629107650272\n"]}]},{"cell_type":"markdown","source":["# Checking GPU"],"metadata":{"id":"Fqf1g1n490Jq"}},{"cell_type":"code","source":["# Check if GPU is available\n","\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","print(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9j0EfIzTxWTG","executionInfo":{"status":"ok","timestamp":1723157681919,"user_tz":420,"elapsed":2,"user":{"displayName":"Akilsurya S","userId":"11381451638417927507"}},"outputId":"42630184-17b6-41b8-a21d-8c8613dedc21"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["cuda:0\n"]}]},{"cell_type":"code","source":["# create a tensor\n","\n","X = torch.tensor([1,2,3,4])\n","X"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wX3BMC-RylVo","executionInfo":{"status":"ok","timestamp":1723157682486,"user_tz":420,"elapsed":569,"user":{"displayName":"Akilsurya S","userId":"11381451638417927507"}},"outputId":"213f1888-c539-4339-bdea-2163c744d1ea"},"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([1, 2, 3, 4])"]},"metadata":{},"execution_count":21}]},{"cell_type":"code","source":["# check the device attribute of the tensor\n","X.device"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zwIzMOPYy67b","executionInfo":{"status":"ok","timestamp":1723157682486,"user_tz":420,"elapsed":6,"user":{"displayName":"Akilsurya S","userId":"11381451638417927507"}},"outputId":"24fa0de3-a7c1-477c-ef8e-f1a633e4769e"},"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cpu')"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","source":["# move device attribute to GPU\n","X.to(device=device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7BhQSq_MzAB1","executionInfo":{"status":"ok","timestamp":1723157682486,"user_tz":420,"elapsed":4,"user":{"displayName":"Akilsurya S","userId":"11381451638417927507"}},"outputId":"6b3ae276-406c-46b1-b771-c64004fdc1c3"},"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([1, 2, 3, 4], device='cuda:0')"]},"metadata":{},"execution_count":23}]},{"cell_type":"code","source":["# it is more efficient to create the tensor on GPU directly\n","Y = torch.tensor([1,2,3,4], device=device)\n","Y"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Lzqb1HaPzJUq","executionInfo":{"status":"ok","timestamp":1723157682486,"user_tz":420,"elapsed":4,"user":{"displayName":"Akilsurya S","userId":"11381451638417927507"}},"outputId":"925fa7b7-aa0a-43d5-d44e-ee8a7782c0b0"},"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([1, 2, 3, 4], device='cuda:0')"]},"metadata":{},"execution_count":24}]},{"cell_type":"code","source":["# check the device attribute of the tensor\n","Y.device"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dI5aDEsIzbbw","executionInfo":{"status":"ok","timestamp":1723157682486,"user_tz":420,"elapsed":3,"user":{"displayName":"Akilsurya S","userId":"11381451638417927507"}},"outputId":"03fc882a-3b99-4db9-946f-e7ce0b94fc5e"},"execution_count":25,"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cuda', index=0)"]},"metadata":{},"execution_count":25}]},{"cell_type":"markdown","source":["## Memory allocation of in-place operations"],"metadata":{"id":"98wycN0mzgkB"}},{"cell_type":"code","source":["# create tensor\n","t1 = torch.randn(10000, 10000, device = \"cpu\") #10000, 10000: the tensor will have a shape of 10000x10000, meaning it will be a 2D tensor with 10000 rows and 10000 columns\n","print(f\" t1: {t1}\")\n","print(f\" t1 length: {len(t1)}\")\n","print(f\" t1 shape: {t1.shape}\")\n","print()\n","\n","# move tensor to GPU\n","t1 = t1.to(device)\n","print(t1.device)\n","\n","# We can use id() function to get memory location of tensor\n","print(f\"initial memory location of tensor t1 is  {id(t1)}\")\n","\n","x=t1\n","print(f\"initial memory location of x is : {id(x)}\")\n","\n","# Waits for everything to finish running\n","torch.cuda.synchronize()\n","\n","# initial memory allocated\n","start_memory = torch.cuda.memory_allocated()\n","\n","# inplace operation\n","t1+=0.1\n","t1.add_(0.1)\n","\n","# since the operation was inplace when we update t1 it will update x as well\n","print(x==t1)\n","\n","print(f\" Final memory location of tensor t1 is: {id(t1)}\")\n","print(f\" final location of x is :{id(x)}\")\n","\n","# Total memory allocated after function call\n","end_memory = torch.cuda.memory_allocated()\n","\n","print(f\"Total memory allocated: {end_memory - start_memory} bytes\")\n","\n","# Memory allocated because of function call\n","memory_allocated = end_memory - start_memory\n","print(memory_allocated / 1024**2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"54m0PDTeznaU","executionInfo":{"status":"ok","timestamp":1723157683487,"user_tz":420,"elapsed":1003,"user":{"displayName":"Akilsurya S","userId":"11381451638417927507"}},"outputId":"24f6185e-849e-443e-e248-32966b67cf78"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":[" t1: tensor([[ 1.2293,  1.1145, -0.1093,  ...,  1.2478,  2.0459,  0.9633],\n","        [ 0.4214,  0.4207, -0.5832,  ..., -0.1143, -0.9691,  1.3124],\n","        [-1.5134,  1.9943, -0.6634,  ..., -0.7071,  1.1182, -0.2489],\n","        ...,\n","        [-1.1518, -0.5882, -0.5358,  ...,  0.6244, -0.5343,  1.0199],\n","        [ 0.6029,  0.3120,  0.1966,  ..., -0.8433,  0.2969,  0.1788],\n","        [-1.3558, -0.7624, -0.7661,  ...,  0.2257,  0.5125, -0.8336]])\n"," t1 length: 10000\n"," t1 shape: torch.Size([10000, 10000])\n","\n","cuda:0\n","initial memory location of tensor t1 is  139629107591136\n","initial memory location of x is : 139629107591136\n","tensor([[True, True, True,  ..., True, True, True],\n","        [True, True, True,  ..., True, True, True],\n","        [True, True, True,  ..., True, True, True],\n","        ...,\n","        [True, True, True,  ..., True, True, True],\n","        [True, True, True,  ..., True, True, True],\n","        [True, True, True,  ..., True, True, True]], device='cuda:0')\n"," Final memory location of tensor t1 is: 139629107591136\n"," final location of x is :139629107591136\n","Total memory allocated: 0 bytes\n","0.0\n"]}]},{"cell_type":"markdown","source":["- From the above example we can see that both x and t1 has same memory location.\n","- when we use in-place operation on t1,it also updates x"],"metadata":{"id":"TdWbmJY42F0A"}},{"cell_type":"markdown","source":["## Memory allocation for out-of-place operations"],"metadata":{"id":"-02HtOZb33vU"}},{"cell_type":"code","source":["# create tensor\n","t2 = torch.randn(10000, 10000, device = \"cpu\")\n","\n","# move tensor to gpu\n","t2 = t2.to(device=device)\n","print(t2.device)\n","\n","# We can use id() function to get memory location of tensor\n","print(f\"initial memory location of tensor t2 {id(t2)}\")\n","\n","y=t2\n","print(f\"final memory location of y is: {id(y)}\")\n","\n","# Waits for everything to finish running\n","torch.cuda.synchronize()\n","\n","# Initial memory allocated\n","start_memory = torch.cuda.memory_allocated()\n","\n","# out-of-place operations\n","t2= t2+0.1\n","\n","# since the operations was not inplace when we update t2, it will not update y\n","print(y==t2)\n","\n","# We can use id() function to get memory location of tensor\n","print(f\"Final memory location of tensor t2 is: {id(t2)}\")\n","print(f\"Final memory location of tensor y is: {id(y)}\")\n","\n","# Total memory allocated after function call\n","end_memory = torch.cuda.memory_allocated()\n","\n","# Memory allocated because of function call\n","memory_allocated = end_memory - start_memory\n","print(memory_allocated / 1024**2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"z33BKVg438uG","executionInfo":{"status":"ok","timestamp":1723157684624,"user_tz":420,"elapsed":1138,"user":{"displayName":"Akilsurya S","userId":"11381451638417927507"}},"outputId":"a9a6a706-10bf-43a9-96e7-4d9311f1fe5b"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["cuda:0\n","initial memory location of tensor t2 139629107652832\n","final memory location of y is: 139629107652832\n","tensor([[False, False, False,  ..., False, False, False],\n","        [False, False, False,  ..., False, False, False],\n","        [False, False, False,  ..., False, False, False],\n","        ...,\n","        [False, False, False,  ..., False, False, False],\n","        [False, False, False,  ..., False, False, False],\n","        [False, False, False,  ..., False, False, False]], device='cuda:0')\n","Final memory location of tensor t2 is: 139629107652352\n","Final memory location of tensor y is: 139629107652832\n","382.0\n"]}]},{"cell_type":"markdown","source":["**Observations from `inplace` and 'out_place' operators**\n","- From the above example we can see that initially both y and t2 has same memory location. After running t2+=0.2, we found that id(t2) points to a different location. This is because Python first evaluates t2+0.2, then allocates new memory for the results.\n","\n","- Since, we have not done in-place operations, updating t2 does not affect y. **y** still points to the same memory location."],"metadata":{"id":"PRjczyGh5oBh"}},{"cell_type":"markdown","source":["## Linear Algebra\n","\n","### Dot Product\n","\n","- *Dot product of 2 vectors x and y is given by the summation of product of elements at the same position*\n","\n","For example:\n","If we have 2 vectors X: [1,2,3,4] and Y:[1,1,2,1]. Then, X.Y will be 1*1 + 2*1 + 3*2 + 4*1 = 13"],"metadata":{"id":"QGwxZdK87Ahi"}},{"cell_type":"code","source":[],"metadata":{"id":"hArOgUfh7nI1","executionInfo":{"status":"ok","timestamp":1723157684624,"user_tz":420,"elapsed":3,"user":{"displayName":"Akilsurya S","userId":"11381451638417927507"}}},"execution_count":27,"outputs":[]}]}